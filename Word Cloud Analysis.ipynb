{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages at once \n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import date\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First load in the speach data frame\n",
    "speeches = pd.read_pickle(\"scores_data_with_party.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is designed to strip out a type of word (default=adjective) in a peice of text \n",
    "# First: Tokenize the text.\n",
    "# Second: Strip out punctuation\n",
    "# Third: Use NLTK to tag them with a part of speech tag\n",
    "# Fourth: Remove stopwords (eg Not, because, everything etc.)\n",
    "# Fifth: Return refined list of words\n",
    "\n",
    "def strip_out_pos(text, pos = ['JJ']):\n",
    "    # First: Tokenize the text.\n",
    "    speech_tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Second: Strip out punctuation\n",
    "    pattern = re.compile(r'[^\\W]') \n",
    "    cleaned_speech_tokens = [item.lower() for item in speech_tokens if re.match(pattern,item)]\n",
    "    \n",
    "    # Third: Use NLTK to tag them with a part of speech tag\n",
    "    speech_tokens_pos_tag = nltk.pos_tag(cleaned_speech_tokens)\n",
    "    speech_tokens_pos = []\n",
    "    for item in speech_tokens_pos_tag:\n",
    "        if item[1] in pos:\n",
    "            if len(item[0])>=5:\n",
    "                if item[0] not in ['thank','applause','laughter','american']:\n",
    "                    speech_tokens_pos.append(item[0])\n",
    "    \n",
    "    # Fourth: Remove stopwords (eg Not, because, everything etc.)\n",
    "    refined_speech_tokens = [item for item in speech_tokens_pos if not item in stopwords.words('english')]\n",
    "\n",
    "    # Fifth: Return refined list of words\n",
    "    return refined_speech_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function combines all of an individual presidents speeches and returns the POS\n",
    "def speech_combiner(president):\n",
    "    dataframe = speeches.loc[speeches['president'] == president]\n",
    "    string_ = \"\"\n",
    "    for row in dataframe['speeches']:\n",
    "        string_ = string_ + str(row)\n",
    "    return strip_out_pos(string_)\n",
    "\n",
    "obama_speech_pos = speech_combiner(\"Barack Obama\")\n",
    "trump_speech_pos = speech_combiner(\"Donald Trump\")\n",
    "\n",
    "def speech_combiner_party(party):\n",
    "    dataframe = speeches.loc[speeches['party'] == party]\n",
    "    string_ = \"\"\n",
    "    for row in dataframe['speeches']:\n",
    "        string_ = string_ + str(row)\n",
    "    return strip_out_pos(string_)\n",
    "\n",
    "rep_pos = speech_combiner_party(\"R\")\n",
    "dem_pos = speech_combiner_party(\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines our word cloud plot\n",
    "# This was adapted from the wordcloud USER DOCUMENTATION\n",
    "# URL: https://amueller.github.io/word_cloud/auto_examples/colored.html\n",
    "\n",
    "def make_image_word_cloud(speech,image):\n",
    "    # put out\n",
    "    image_array = np.array(Image.open(image))\n",
    "    image_colors = ImageColorGenerator(image_array)\n",
    "    \n",
    "    wc = WordCloud(background_color=\"white\",max_words = 50,mask=image_array, max_font_size=120)\n",
    "    wc.generate(str(speech))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(35,35))\n",
    "    axes[0].imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "    axes[1].imshow(image_array,cmap=plt.cm.gray, interpolation=\"bilinear\")\n",
    "    axes[0].set_axis_off()\n",
    "    axes[1].set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_image_word_cloud(obama_speech_pos,'Pictures for Word Cloud/obama.png')\n",
    "make_image_word_cloud(trump_speech_pos,'Pictures for Word Cloud/trump.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_word_cloud(rep_pos,'Pictures for Word Cloud/repu.png')\n",
    "make_image_word_cloud(dem_pos,'Pictures for Word Cloud/dem.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
