{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup #use beautifulsoup to scrape data\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "url = \"http://millercenter.org/the-presidency/presidential-speeches\"\n",
    "\n",
    "browser = webdriver.Chrome() #change this line depending on your system\n",
    "browser.get(url) #go to the website \n",
    "\n",
    "\n",
    "#This is what we will change if we want the whole data. Right now it only runs for 44th president\n",
    "\n",
    "for i in range(40,41):\n",
    "    x = i\n",
    "    absolutepath_president = f'/html/body/div[2]/div/main/div[2]/div/div[2]/article/div/div[2]/div/div/div/form/div[3]/fieldset/div/div/div/div[{x}]/label'\n",
    "    president1 = browser.find_element_by_xpath(absolutepath_president)\n",
    "    president1.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SCROLL_PAUSE_TIME = 0.8\n",
    "\n",
    "\n",
    "#slight changes to be made!!\n",
    "\n",
    "# Get scroll height\n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dates                                           speeches  \\\n",
      "0  1993-01-05  [Thank you all very much. Good luck. Please be...   \n",
      "1  1992-12-15  [Thank you all for that welcome back. Thank yo...   \n",
      "2  1992-12-04  [I want to talk to you today about the tragedy...   \n",
      "3  1992-10-11  [Jim Lehrer. Good evening, and welcome to the ...   \n",
      "4  1992-08-20  [Thank you all very much. Thank you, thank you...   \n",
      "5  1992-01-28  [Mr. Speaker and Mr. President, distinguished ...   \n",
      "6  1991-07-31  [President Gorbachev. Good evening, ladies and...   \n",
      "7  1991-03-06  [Mr. President. And Mr. Speaker, thank you, si...   \n",
      "8  1991-02-27  [Kuwait is liberated. Iraq's army is defeated....   \n",
      "9  1991-01-29  [Mr. President and Mr. Speaker and members of ...   \n",
      "10 1991-01-16  [Just 2 hours ago, allied air forces began an ...   \n",
      "11 1990-10-02  [Tonight I want to talk to you about a problem...   \n",
      "12 1990-10-01  [Mr. President, thank you very much. Mr. Secre...   \n",
      "13 1990-09-11  [Mr. President and Mr. Speaker and Members of ...   \n",
      "14 1990-08-08  [In the life of a nation, we're called upon to...   \n",
      "15 1990-07-26  [Evan, thank you so much. And welcome to every...   \n",
      "16 1990-01-31  [Mr. President, Mr. Speaker, members of the Un...   \n",
      "17 1989-12-20  [My fellow citizens, last night I ordered U.S....   \n",
      "18 1989-05-12  [Thank you, Governor. Thank you all very much ...   \n",
      "19 1989-02-09  [Mr. Speaker, Mr. President, and distinguished...   \n",
      "20 1989-01-20  [Mr. Chief Justice, Mr. President, Vice Presid...   \n",
      "21 1988-09-25  [JIM LEHRER: Good evening. On behalf of the Co...   \n",
      "22 1988-08-18  [I have many friends to thank tonight. I thank...   \n",
      "\n",
      "            president  \n",
      "0   George H. W. Bush  \n",
      "1   George H. W. Bush  \n",
      "2   George H. W. Bush  \n",
      "3   George H. W. Bush  \n",
      "4   George H. W. Bush  \n",
      "5   George H. W. Bush  \n",
      "6   George H. W. Bush  \n",
      "7   George H. W. Bush  \n",
      "8   George H. W. Bush  \n",
      "9   George H. W. Bush  \n",
      "10  George H. W. Bush  \n",
      "11  George H. W. Bush  \n",
      "12  George H. W. Bush  \n",
      "13  George H. W. Bush  \n",
      "14  George H. W. Bush  \n",
      "15  George H. W. Bush  \n",
      "16  George H. W. Bush  \n",
      "17  George H. W. Bush  \n",
      "18  George H. W. Bush  \n",
      "19  George H. W. Bush  \n",
      "20  George H. W. Bush  \n",
      "21  George H. W. Bush  \n",
      "22  George H. W. Bush  \n"
     ]
    }
   ],
   "source": [
    "import urllib3 \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "link_str = []\n",
    "\n",
    "for link in soup.findAll('a', href=True):\n",
    "    if link != None:\n",
    "        link_str.append(link['href'])\n",
    "\n",
    "# now I want the link strings containting /the-presidency/\n",
    "new_link_str = []\n",
    "\n",
    "for element in link_str:\n",
    "    if element.find(\"/presidential-speeches/\") >= 0: \n",
    "        new_link_str.append(element)\n",
    "        \n",
    "\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "list2=[]\n",
    "president_names=[]\n",
    "for element in new_link_str:\n",
    "    url = \"http://millercenter.org\" + element\n",
    "#     print(element)\n",
    "    response = http.request('GET', url)\n",
    "    soup_2 = BeautifulSoup(response.data, 'lxml')\n",
    "    list2.append(soup_2.findAll('div', {\"class\":\"transcript-inner\"}))\n",
    "    president_names.append(soup_2.find('p', {\"class\":\"president-name\"}).get_text(strip=True))\n",
    "    \n",
    "\n",
    "\n",
    "#converting into string due to weird beautifulsoup output    \n",
    "list3=[]\n",
    "for i in range(len(list2)):\n",
    "    if list2[i]:\n",
    "        list3.append(str(list2[i]))\n",
    "    else:\n",
    "        \n",
    "        #add comments for why I had to do it like this\n",
    "        \n",
    "        url = \"http://millercenter.org\" + new_link_str[i]\n",
    "        response = http.request('GET', url)\n",
    "        soup_2 = BeautifulSoup(response.data, 'lxml')\n",
    "        list3.append(str(soup_2.findAll('div', {\"class\":\"view-transcript\"})))\n",
    "\n",
    "# print(list3[1])\n",
    "\n",
    "#this will be used to clean the text from html tags\n",
    "def tag_cleanr(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', text)\n",
    "    return cleantext\n",
    "\n",
    "cleaned_speeches = []\n",
    "\n",
    "#these replace lines could and should be replaced with regex since we covered that in the syllabus more extensively\n",
    "\n",
    "for i in range(len(list3)):\n",
    "    x = tag_cleanr(list3[i])\n",
    "    x = x.replace('Transcript', '').replace('\\r\\n', '').replace('\\n', '')\n",
    "    cleaned_speeches.append(x)\n",
    "\n",
    "\n",
    "#Get all the speech dates into a list\n",
    "\n",
    "pattern = r'(\\w+-\\d+-\\d{4})'\n",
    "speech_dates=[]\n",
    "\n",
    "\n",
    "for i in range(len(new_link_str)):\n",
    "    match = re.findall(pattern, new_link_str[i])\n",
    "    speech_dates.append(str(match))\n",
    "\n",
    "\n",
    "for i in range(len(speech_dates)):\n",
    "    #this feels like its terrible syntax but not sure if there is a nicer way, maybe I will replace it with regex\n",
    "    \n",
    "    speech_dates[i] = speech_dates[i].replace('[', '').replace(']', ''.replace(\"'\", \"\")).replace(\"'\", \"\")\n",
    "    speech_dates[i] = datetime.strptime(speech_dates[i], '%B-%d-%Y')\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'dates':speech_dates, 'speeches':cleaned_speeches, 'president':president_names})\n",
    "\n",
    "#this part is added because dataframe does not recognize [] as an empty input. \n",
    "\n",
    "df['speeches'].replace('[]', np.nan, inplace=True)\n",
    "\n",
    "#now that I replaced [] with NaN, I can simply say drop all the rows with NaN elements\n",
    "\n",
    "df.dropna(subset=['speeches'], inplace=True)\n",
    "\n",
    "\n",
    "        \n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
